\section{Objection 3: Populations act upon their own interests / are selfish}

make clear in which case this matters: neither rawls nor avg util – also zb was? 

während bei (2) der neutral range auf eine zahl verengt wird, wird er in (3) ausgedehnt, sodass alles neutral ist 

The difference principle and average utilitarianism are probably the two most prominent welfare functions. In both of them the argument against neutrality does not hold for different reasons. Yet, although these frameworks are so well received, they both suffer from a justificatory problem. The specific justificatory problem which matters in our context is that the frameworks assume a universal moral domain. This means that they assume that in the first place every person should receive moral consideration. The universal domain is what I will question in this objection and it will lead to another solution of (response to) the argument against neutrality.  

So far we have interpreted the intuition of neutrality as a principle which is applied only in a particular instance of comparing the welfare of two scenario: Whenever there are additional persons in one scenario who do not exist in the other scenario, then we can apply the intuition of neutrality. This is reflected in the conclusions in Proof 1. In (C3) and (C4) we have used the intuition of neutrality because there is a different number of persons in scenario A than there is in scenarios B and C. But we have not used the intuition in (C7) because we have been comparing scenarios B and C, and these scenarios have the same number of persons: “B and C contain the very same five people, so in comparing their values all five count as existing people.” (\label{ref:RNDdoGn25412e}Broome 2012, p.177; this has been marked as potentially problematic in a talk with Stefan Fischer.) 

A simple solution to the argument against against neutrality is to deny that in such cases all people count as existing people. If we regard person q (the person who exists in scenarios B and C only) as non-existent, then we cannot derive that C is better than B by direct comparison (C7), and the argument fails: (explain ‘ notation briefly) 
\begin{comment}
\ \ (C7’)\ \ (A1) ${\wedge}$ (A2) ${\wedge}$ (A3) \ $\Rightarrow $ \ uB(P0) {\textgreater} uC(P0) 

\ \ (C8’)\ \ (C7’) ${\wedge}$ (P1) \ $\Rightarrow $ \ uB(P0 ${\cup}$ P+) {\textgreater} uC(P0 ${\cup}$ P+) 

\ \ (C9’)\ \ (C4) \ $\Leftrightarrow $ \ (C8) 
\end{comment}
This requires a revised version of the intuition of neutrality (P1). The only thing which is different from Def. 2 is that the intuition has been extended to comparisons of scenarios where the number of persons is the same: (very unclear! there is no numbers in the formula) 

Definition 7: The intuition of neutrality (revised) 
\begin{comment}
${\exists}$u1, u2: ( ${\forall}$ x ${\in}$ P+ : uB(x) ${\in}$ [u1, u2] ) \ding{213} 

( uB(P0) {\textgreater} uA(P0) \ \ \ding{213} \ \ uB(P0 ${\cup}$ P+) {\textgreater} uA(P0 ${\cup}$ P+) ) ${\wedge}$  

( uB(P0) {\textless} uA(P0) \ \ \ding{213} \ \ uB(P0 ${\cup}$ P+) {\textless} uA(P0 ${\cup}$ P+) ) 
\end{comment}

But while this solution is compelling so far, it brings with it a formal problem. Thus far, we have not really needed to specify P0 and P+ any more than what is implicit in Def. 2: P0 is the population which exists in both scenarios and P+ is the population which exists only in scenario B. This is no longer implicit in Def. 7: P0 and P+ both exist in both scenarios. (this should probs go before the definition) There is no formal way to distinguish them. P+ are the people who are neutral with respect to general welfare if their well-being lies within the neutral range. And P+ are the same people in B and in C. But P+ could be any persons: P+ could be all persons, no persons, or an arbitrary selection of persons. So as they are not already formally specified we need to specify P+. It is obvious how we specify them:  

\ \ Definition 8: Additional specification of the intuition of neutrality 

\ \ P0 are the existing people and P+ are the non-existing people.  

Unlike all the formal definitions above, this is a material definition, which is not a problem. The problem is that it is also a relative definition. Which people are existing and which are not depends on the time of evaluation. When we consider whether it is good or not that a baby is born, we arrive at different evaluations before and after the pregnancy of the baby’s parent. Before the pregnancy, the baby’s well-being has to be ignored because of the intuition of neutrality, but after the pregnancy, the baby’s well-being has to be considered. Imagine that we want to know whether it is positive or negative for the general welfare whether the baby suffers from a chronic disease. Then before the pregnancy we will derive that the chronic disease is neutral with respect to general welfare and after the pregnancy we will derive that it would be better for general welfare if the baby does not suffer from a such disease (is better / would have been better).  

More formally, the evaluation of welfare depends on what scenario we use as a base scenario based on which we judge which persons are existent and which are not. Such a base scenario may be either of the scenarios which we compare, or a third scenario. In the case of the argument of neutrality, we need to choose scenario A as our base scenario so that we can arrive at the alternative conclusion (C8’). 

\ \ (P5’)\ \ A is the base scenario, \newline \ \ \ \ uA is the distribution of well-being of the base scenario.  

So, to be more precise, I revise (C8’) and include (P5’) as a premise:  

(C8’)\ \ (C7’) ${\wedge}$ (P1) ${\wedge}$ (P5’) \ $\Rightarrow $ \ uB(P0 ${\cup}$ P+) {\textgreater} uC(P0 ${\cup}$ P+) 

A similar approach (how is it different?) to this relativism [in what sense?] is pursued in \label{ref:RNDLLbEezdHvh}Broome 2004, pp. 157-162. There it is discarded for two reasons: First, because of the inconsistencies which arise when switching the base scenario (pp. 68-76). Second, because of the difficulty to ethically justify person-relativity or community-relativity (p. 161f). I will now address both issues.  

The problem of inconsistency cannot be denied: If ethical evaluations of welfare depend on the choice of the base scenario and if every person chooses the person’s own situation as the base scenario, inconsistencies will arise. Principally, there are inconsistencies of several kinds. One person could contradict another person from the same population. As we are concerned with population ethics here, where persons will usually somehow consider the whole population for their evaluation, this is not necessarily a problem. A necessary problem is the time-dependence of the evaluation, which is pointed out in \label{ref:RND8yvQ79TSk8}Broome 2004, p. 75: “You choose rightly, but it later turns out you chose wrongly. Indeed, it may turn out that you ought later to undo what you rightly did. Moreover, you might be able to foresee even as you choose A that just this would happen. This is a most implausible sort of incoherence in your activity.” This sounds like a problem at first, but in fact it is well acceptable.  

(one WEAK possible objection is the idea that) There is no such thing as inconsistency between actions. (This needs SEP backing!!) Such a concept exists of course symbolically, and for example when two persons or one person act out two actions which appear to follow opposite intentions, we might say that the actions are inconsistent. But the concept is very fuzzy and the existing theory of rationality does not provide a criterion for identifying inconsistent actions. What the theory of rationality does provide, is a criterion for identifying inconsistent beliefs: Beliefs are inconsistent if their propositions are contradictory. Without a formal theory of inconsistent actions, philosophers should probably restrict themselves to the analysis of inconsistent beliefs, not actions. (not yet, but why couldn’t there be one?) The underlying beliefs are complex: Before the action A, we think that we should do A. And we think that as a causal effect of doing A, we will regret having done A. So we think that we should do A, and that we will regret it afterwards. After the action A, we think that we should not have done A. We also think that we have thought that we should do A. There is no formal contradiction in these beliefs. It may very well be rational to think A at the moment and to expect that oneself would think the opposite of A under different circumstances. As the enactment of A causes a change of circumstances, the above beliefs may come about, and there is nothing wrong with them. There is also no such thing as a problem of “undoing” an action in philosophical terms. A is done within one set of circumstances and then within another set of circumstances is “undone”. The two actions of “doing A” and “undoing A” can be differentiated by the fact that they have taken place within different contexts (one context without the causal effects of A and one context with the causal effects of A). There is no reason to ignore the contexts of the actions and to strip them down to the notions of “doing A” and “undoing A”.  

Let us examine two examples where we ignore any ethical constraints and just consider the consistency of their beliefs. Imagine a community of two persons who reason whether or not they should improve some genetic condition of their child. They may be concerned about the well-being of the family and think: “Our family is rather against this for religious reasons. Once the child is born, it will clearly prefer that the modification had taken place. Our family will then have to respect the preferences of the child. As a result, our family will think that the modification should have taken place; and if it will not have taken place, our family will probably be very unhappy about it.” The parents in their situation of reasoning should then consider whether they want to experience this later unhappiness. But there is no rule of rationality which would require them to somehow align the present and future preferences of the family. After all, the family will consist of different persons after the child is born. As a second example, imagine a direct democracy called Alphaland whose citizens consider – because of their liberal ideal – to invade and annex an autocratic country called Betaland with a population bigger than their own population. They consensually adopt a resolution: “Alphaland wants to annex Betaland. Alphaland expects Betaland to condemn the violence related to the annexation. As the current citizens of Betaland will be the majority in Alphaland after the annexation, we expect that Alphaland will officially regret the annexation afterwards. But we expect that most former Betaland citizens will nonetheless want to remain in Alphaland for pragmatic reasons (so there is no reason against the action).” Rationality does not require present Alphaland to consider the interest future Alphaland. After all, future Alphaland is made up of different citizens than present Alphaland. These examples illustrate that there is no requirement for communities to be consistent with their beliefs and expected beliefs over time. (Whether this principle also applies to individual agents is up for discussion, but luckily needs not concern us here.) 

hier deutlicher das problem auspointen: communities erscheinen, zb weil sie namen haben, wie menschen. dabei gelten viel weniger strenge regeln zb bzgl konsistenz (vgl auch arrow). ob community denken gut ist, bleibt offen, aber es passiert ja offenbar. evtl wäre der absatz über diesem ein argument gegen solches community denken (will ich nicht FÜR community denken plädieren?) 

I have just talked about the consistency of beliefs of communities. But we are here concerned with general ethical belief, which one would assume to be independent from the practical belief of some community. (bessere überleitung) This disparity is the subject of the second objection to relativism: Ethics is nothing related to the welfare of any community, but it is related to the welfare of all – ethics has a universal domain.  

\begin{itemize} \item i do \_not\_ want to say that ethics applies population-wise (as one could think from my examples above). it applies of course to the complete domain of humans, because all humans have similar interests (\label{ref:RNDitrDlHBuIn}Stemmer 2000). \item infer intuition of neutrality with a real range from egoistic interests 

\begin{itemize} \item it is unlikely that all or many people would grant rights to nonexisting \item there is no per se effect of happiness on other people’s happiness, but in the extremes it is highly likely 

\begin{itemize} \item mitleidsethik \item psychological problem: people do not evaluate the effect of mitleid as a change of their own welfare, but as a change of global welfare!  \item {}-{\textgreater} revisionism: when these effects are really properly included in the welfare function, then we can have an ion that they are completely irrelevant \end{itemize} \end{itemize} \end{itemize}